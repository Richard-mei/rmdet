model:
  backbone:
    [
      [ -1, Conv, 1, [ 3, 64, 7, 2 ] ],
      [ -1, nn.MaxPool2d, 1, [ 3, 2 ] ],
      [ -1, Res_Stage, 2, [ 64, 64, 1, BasicBlock] ],  # args: [c_in, c_out, stride, block]  insert n to index 2.
      [ -1, Res_Stage, 2, [ 64, 128, 2, BasicBlock] ],
      [ -1, Res_Stage, 2, [ 128, 256, 2, BasicBlock] ],
      [ -1, Res_Stage, 2, [ 256, 512, 2, BasicBlock] ]
    ]

  neck:
    [
      [ -1, nn.Conv2d, 1, [ 512, 256, 1, 1 ] ],
      [ [ -1, 4 ], FPNBlock, 1, [ 256, 256, 1, 1 ] ],
      [ [ -1, 3 ], FPNBlock, 1, [ 128, 256, 1, 1 ] ],
      [ -1, nn.Conv2d, 1, [ 256, 256, 3, 1, 1 ] ],
      [ 7, nn.Conv2d, 1, [ 256, 256, 3, 1, 1 ] ],
      [ 6, nn.Conv2d, 1, [ 256, 256, 3, 1, 1 ] ],
      [ -1, nn.Conv2d, 1, [ 256, 256, 3, 2, 1 ] ],
      [ -1, nn.Conv2d, 1, [ 256, 256, 3, 2, 1 ] ]
    ]

  head:
    [
      [ [ 9, 10, 11, 12, 13 ], RetinaHead, 1, [ 256, 256, False] ]
    ]


optimizer:
  cfg: 'SGD'
  lr: 0.0008
  momentum: 0.9
  weight_decay: 0.0001


dataset:
  base:
    cfg: 'VOCDataset'
    CLASSES_NAME: [ "__background__ ","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair","cow","diningtable","dog",
                    "horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor" ]
    img_sizes: [416, 416]
    root_dir: 'I:/DataSets/VOCdevkit0712/VOCdevkit'
  train:
    batch_size: 4
    is_train: True
    set_: "[('2007', 'trainval')]"
  eval:
    batch_size: 1
    is_train: False
    set_: "[('2007', 'test')]"

loss:
  cfg: 'retina_loss'
  cls_loss:
    cfg: 'focal_loss'
    alpha: 0.25
    gamma: 2.0
  reg_loss:
    cfg: 'GIoU'

generator:
  cfg: 'Anchor_Gen'
  strides: [8, 16, 32, 64, 128]
  ratios: [0.5, 1, 2]
  scales: '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'
  base_sizes: [16, 32, 64, 128, 256]
  scale_major: True
  #centers: None,
  center_offset: 0.


#generator:
#  cfg: 'Horizontal_Generator'
#  ratios: [0.5, 1, 2]
#  scales: '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'
#  strides: [8, 16, 32, 64, 128]
##    sizes: [32, 64, 128, 256, 512]
#  sizes: [16, 32, 64, 128, 256]



hyp:
  cls_pw: 1.0  # cls BCELoss positive_weight
  obj_pw: 1.0  # obj BCELoss positive_weight
  fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)


#dataset_train:
#      cfg: 'VOCDataset'
#      CLASSES_NAME: [ "__background__ ","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair","cow","diningtable","dog",
#                      "horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor" ]
#      batch_size: 4
#      img_sizes: [480, 640]
#      train_set: "[('2007', 'trainval')]"
#      root_dir: 'H:/DataSets/VOCdevkit0712/VOCdevkit'
#      is_train: True
#
#dataset_eval:
#      cfg: 'VOCDataset'
#      CLASSES_NAME: ["__background__ ","aeroplane","bicycle","bird","boat","bottle","bus","car","cat","chair","cow","diningtable","dog",
#                      "horse","motorbike","person","pottedplant","sheep","sofa","train","tvmonitor"]
#      batch_size: 1
#      img_sizes: [480, 640]
#      train_set: "[('2007', 'test')]"
#      root_dir: 'H:/DataSets/VOCdevkit0712/VOCdevkit'
#      is_train: False
cfg: 'retinanet-fpn-r18'